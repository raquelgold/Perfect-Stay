{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82515688-07f9-46a0-8fa5-76f70246a2e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc8cab3d-58e2-48b5-8c03-702846963148",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2.0.0 in /databricks/python3/lib/python3.11/site-packages (1.23.5)\nCollecting pyrosm\n  Downloading pyrosm-0.6.2.tar.gz (2.5 MB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/2.5 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[91m━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.2/2.5 MB\u001B[0m \u001B[31m5.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.2/2.5 MB\u001B[0m \u001B[31m18.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m2.5/2.5 MB\u001B[0m \u001B[31m27.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.5/2.5 MB\u001B[0m \u001B[31m20.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25h  Installing build dependencies: started\n  Installing build dependencies: still running...\n  Installing build dependencies: finished with status 'done'\n  Getting requirements to build wheel: started\n  Getting requirements to build wheel: finished with status 'done'\n  Preparing metadata (pyproject.toml): started\n  Preparing metadata (pyproject.toml): finished with status 'done'\nCollecting python-rapidjson (from pyrosm)\n  Obtaining dependency information for python-rapidjson from https://files.pythonhosted.org/packages/99/8f/fb06132f7dc816b9689d43294bf58dd979da702cbdfe9fb265c5e7d54e6f/python_rapidjson-1.23-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata\n  Downloading python_rapidjson-1.23-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (24 kB)\nRequirement already satisfied: setuptools>=18.0 in /databricks/python3/lib/python3.11/site-packages (from pyrosm) (68.0.0)\nCollecting geopandas>=0.12.0 (from pyrosm)\n  Obtaining dependency information for geopandas>=0.12.0 from https://files.pythonhosted.org/packages/54/e4/fac19dc34cb686c96011388b813ff7b858a70681e5ce6ce7698e5021b0f4/geopandas-1.1.2-py3-none-any.whl.metadata\n  Downloading geopandas-1.1.2-py3-none-any.whl.metadata (2.3 kB)\nCollecting shapely>=2.0.1 (from pyrosm)\n  Obtaining dependency information for shapely>=2.0.1 from https://files.pythonhosted.org/packages/13/02/58b0b8d9c17c93ab6340edd8b7308c0c5a5b81f94ce65705819b7416dba5/shapely-2.1.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n  Downloading shapely-2.1.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.8 kB)\nCollecting cykhash (from pyrosm)\n  Downloading cykhash-2.0.1.tar.gz (44 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/44.9 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m44.9/44.9 kB\u001B[0m \u001B[31m3.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25h  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Getting requirements to build wheel: started\n  Getting requirements to build wheel: finished with status 'done'\n  Preparing metadata (pyproject.toml): started\n  Preparing metadata (pyproject.toml): finished with status 'done'\nCollecting pyrobuf (from pyrosm)\n  Using cached pyrobuf-0.9.3-cp311-cp311-linux_x86_64.whl\nCollecting numpy<2.0.0\n  Obtaining dependency information for numpy<2.0.0 from https://files.pythonhosted.org/packages/3a/d0/edc009c27b406c4f9cbc79274d6e46d634d139075492ad055e3d68445925/numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/61.0 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.0/61.0 kB\u001B[0m \u001B[31m5.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting pyogrio>=0.7.2 (from geopandas>=0.12.0->pyrosm)\n  Obtaining dependency information for pyogrio>=0.7.2 from https://files.pythonhosted.org/packages/89/a4/0aef5837b4e11840f501e48e01c31242838476c4f4aff9c05e228a083982/pyogrio-0.12.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n  Downloading pyogrio-0.12.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.11/site-packages (from geopandas>=0.12.0->pyrosm) (23.2)\nCollecting pandas>=2.0.0 (from geopandas>=0.12.0->pyrosm)\n  Obtaining dependency information for pandas>=2.0.0 from https://files.pythonhosted.org/packages/bf/c9/63f8d545568d9ab91476b1818b4741f521646cbdd151c6efebf40d6de6f7/pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata\n  Downloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/91.2 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m91.2/91.2 kB\u001B[0m \u001B[31m8.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting pyproj>=3.5.0 (from geopandas>=0.12.0->pyrosm)\n  Obtaining dependency information for pyproj>=3.5.0 from https://files.pythonhosted.org/packages/ad/ab/9bdb4a6216b712a1f9aab1c0fcbee5d3726f34a366f29c3e8c08a78d6b70/pyproj-3.7.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n  Downloading pyproj-3.7.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (31 kB)\nRequirement already satisfied: jinja2>=2.8 in /databricks/python3/lib/python3.11/site-packages (from pyrobuf->pyrosm) (3.1.2)\nRequirement already satisfied: cython>=0.23 in /databricks/python3/lib/python3.11/site-packages (from pyrobuf->pyrosm) (0.29.32)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.11/site-packages (from jinja2>=2.8->pyrobuf->pyrosm) (2.1.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /databricks/python3/lib/python3.11/site-packages (from pandas>=2.0.0->geopandas>=0.12.0->pyrosm) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas>=2.0.0->geopandas>=0.12.0->pyrosm) (2022.7)\nCollecting tzdata>=2022.7 (from pandas>=2.0.0->geopandas>=0.12.0->pyrosm)\n  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/c7/b0/003792df09decd6849a5e39c28b513c06e84436a54440380862b5aeff25d/tzdata-2025.3-py2.py3-none-any.whl.metadata\n  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.11/site-packages (from pyogrio>=0.7.2->geopandas>=0.12.0->pyrosm) (2023.7.22)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->geopandas>=0.12.0->pyrosm) (1.16.0)\nDownloading geopandas-1.1.2-py3-none-any.whl (341 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/341.7 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m341.7/341.7 kB\u001B[0m \u001B[31m28.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/18.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.3/18.3 MB\u001B[0m \u001B[31m70.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.3/18.3 MB\u001B[0m \u001B[31m75.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.3/18.3 MB\u001B[0m \u001B[31m79.2 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11.2/18.3 MB\u001B[0m \u001B[31m79.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━\u001B[0m \u001B[32m15.1/18.3 MB\u001B[0m \u001B[31m90.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m98.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m98.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m98.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m98.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m18.3/18.3 MB\u001B[0m \u001B[31m43.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading shapely-2.1.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.1 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.1 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m3.1/3.1 MB\u001B[0m \u001B[31m117.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.1/3.1 MB\u001B[0m \u001B[31m56.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading python_rapidjson-1.23-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.7 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m62.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/12.8 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.9/12.8 MB\u001B[0m \u001B[31m85.9 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.7/12.8 MB\u001B[0m \u001B[31m82.2 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━\u001B[0m \u001B[32m8.8/12.8 MB\u001B[0m \u001B[31m84.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━\u001B[0m \u001B[32m12.1/12.8 MB\u001B[0m \u001B[31m87.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m83.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m83.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m51.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading pyogrio-0.12.1-cp311-cp311-manylinux_2_28_x86_64.whl (32.5 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/32.5 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.8/32.5 MB\u001B[0m \u001B[31m85.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.4/32.5 MB\u001B[0m \u001B[31m64.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.2/32.5 MB\u001B[0m \u001B[31m68.2 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.7/32.5 MB\u001B[0m \u001B[31m68.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.2/32.5 MB\u001B[0m \u001B[31m66.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.1/32.5 MB\u001B[0m \u001B[31m66.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m16.3/32.5 MB\u001B[0m \u001B[31m64.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━\u001B[0m \u001B[32m20.3/32.5 MB\u001B[0m \u001B[31m74.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━\u001B[0m \u001B[32m23.9/32.5 MB\u001B[0m \u001B[31m84.9 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━\u001B[0m \u001B[32m27.0/32.5 MB\u001B[0m \u001B[31m91.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━\u001B[0m \u001B[32m30.1/32.5 MB\u001B[0m \u001B[31m81.9 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m32.5/32.5 MB\u001B[0m \u001B[31m84.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m32.5/32.5 MB\u001B[0m \u001B[31m84.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m32.5/32.5 MB\u001B[0m \u001B[31m84.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m32.5/32.5 MB\u001B[0m \u001B[31m84.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m32.5/32.5 MB\u001B[0m \u001B[31m84.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m32.5/32.5 MB\u001B[0m \u001B[31m84.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m32.5/32.5 MB\u001B[0m \u001B[31m30.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading pyproj-3.7.2-cp311-cp311-manylinux_2_28_x86_64.whl (9.5 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/9.5 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.0/9.5 MB\u001B[0m \u001B[31m91.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m \u001B[32m7.8/9.5 MB\u001B[0m \u001B[31m91.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m9.5/9.5 MB\u001B[0m \u001B[31m92.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.5/9.5 MB\u001B[0m \u001B[31m64.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/348.5 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m348.5/348.5 kB\u001B[0m \u001B[31m22.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hBuilding wheels for collected packages: pyrosm, cykhash\n  Building wheel for pyrosm (pyproject.toml): started\n  Building wheel for pyrosm (pyproject.toml): still running...\n  Building wheel for pyrosm (pyproject.toml): finished with status 'done'\n  Created wheel for pyrosm: filename=pyrosm-0.6.2-cp311-cp311-linux_x86_64.whl size=7006356 sha256=be7e45d8ee16b4c299155a59b9b03ce12da2d228479dd68df92c39d16c7d2fb2\n  Stored in directory: /root/.cache/pip/wheels/f3/77/c3/7b767c229a2bba06eb2e47fbce4cdbc4490b38d97f2a0ae64d\n  Building wheel for cykhash (pyproject.toml): started\n  Building wheel for cykhash (pyproject.toml): finished with status 'done'\n  Created wheel for cykhash: filename=cykhash-2.0.1-cp311-cp311-linux_x86_64.whl size=3000204 sha256=bfa221270a5d83e89ea6369cb9d6b42111772edecc28a4cb13abbc8a8176f664\n  Stored in directory: /root/.cache/pip/wheels/90/a9/f2/e3f11549a5a2b1fd756c1e05c8f90855635ba95e46bd1f4d03\nSuccessfully built pyrosm cykhash\nInstalling collected packages: cykhash, tzdata, python-rapidjson, pyproj, numpy, shapely, pyrobuf, pyogrio, pandas, geopandas, pyrosm\n  Attempting uninstall: tzdata\n    Found existing installation: tzdata 2022.1\n    Not uninstalling tzdata at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-03c330ea-65d2-45be-b792-d232e9aa7e92\n    Can't uninstall 'tzdata'. No files were found to uninstall.\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.23.5\n    Not uninstalling numpy at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-03c330ea-65d2-45be-b792-d232e9aa7e92\n    Can't uninstall 'numpy'. No files were found to uninstall.\n  Attempting uninstall: pandas\n    Found existing installation: pandas 1.5.3\n    Not uninstalling pandas at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-03c330ea-65d2-45be-b792-d232e9aa7e92\n    Can't uninstall 'pandas'. No files were found to uninstall.\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npetastorm 0.12.1 requires pyspark>=2.1.0, which is not installed.\nnumba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.5.1 requires pandas!=1.4.0,<2.1,>1.1, but you have pandas 2.3.3 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0mSuccessfully installed cykhash-2.0.1 geopandas-1.1.2 numpy-1.26.4 pandas-2.3.3 pyogrio-0.12.1 pyproj-3.7.2 pyrobuf-0.9.3 pyrosm-0.6.2 python-rapidjson-1.23 shapely-2.1.2 tzdata-2025.3\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install \"numpy<2.0.0\" pyrosm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53f6dfa2-3b9c-43a0-bf3d-243a32fee139",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc391578-2444-46f6-a46c-a60336452d33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c58ac0a-429d-44b4-b1e9-2a8376355cc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded.\nProcessing regions: ['Andorra', 'Liechtenstein', 'Malta', 'Monaco', 'Cyprus', 'Luxembourg']\nFiltering OpenStreetMap data for amenity types: {'amenity': ['bar', 'pub', 'biergarten', 'nightclub']}\nOutput Delta table: world_data_distributed\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from pyrosm import OSM, get_data\n",
    "from pyspark.sql.functions import pandas_udf, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "import os\n",
    "\n",
    "# Parameters\n",
    "REGIONS_LIST = [\"Andorra\", \"Liechtenstein\", \"Malta\", \"Monaco\", \"Cyprus\", \"Luxembourg\"]\n",
    "OUTPUT_TABLE_NAME = \"world_data_distributed\"\n",
    "TAGS = {'amenity': ['bar', 'pub', 'biergarten', 'nightclub']}\n",
    "\n",
    "# Schema Configuration\n",
    "result_schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"amenity\", StringType(), True),\n",
    "    StructField(\"latitude\", DoubleType(), True),\n",
    "    StructField(\"longitude\", DoubleType(), True),\n",
    "    StructField(\"source_region\", StringType(), True)\n",
    "])\n",
    "\n",
    "print(f\"Configuration loaded.\")\n",
    "print(f\"Processing regions: {REGIONS_LIST}\")\n",
    "print(f\"Filtering OpenStreetMap data for amenity types: {TAGS}\")\n",
    "print(f\"Output Delta table: {OUTPUT_TABLE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "169a8de4-bd50-4f1c-b0a3-8f4d9d2c893f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Data Processing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "950a5c6f-0832-45c8-9b36-272fd712edc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing function defined.\n"
     ]
    }
   ],
   "source": [
    "# Processing Function (Runs on Workers)\n",
    "def process_region_batch(pdf_chunk):\n",
    "    \"\"\"\n",
    "    Receives a list of regions (pandas DataFrame) and processes them.\n",
    "    This function runs in parallel on the cluster workers.\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    # Local download directory on the worker node\n",
    "    worker_download_dir = \"/tmp/osm_data_worker\"\n",
    "    if not os.path.exists(worker_download_dir):\n",
    "        os.makedirs(worker_download_dir)\n",
    "\n",
    "    # Iterate over regions assigned to this worker\n",
    "    for region_name in pdf_chunk['region_name']:\n",
    "        try:\n",
    "            # Data Acquisition\n",
    "            # Using get_data within worker to ensure local file access\n",
    "            fp = get_data(region_name, directory=worker_download_dir)\n",
    "            osm = OSM(fp)\n",
    "            \n",
    "            # Parsing data\n",
    "            # Using the same filter as local version\n",
    "            gdf = osm.get_pois(custom_filter=TAGS)\n",
    "            \n",
    "            # Geometry Processing\n",
    "            if not gdf.empty:\n",
    "                # Project to UTM -> Centroid -> Back to WGS84\n",
    "                gdf_projected = gdf.to_crs(gdf.estimate_utm_crs())\n",
    "                gdf_projected['geometry'] = gdf_projected.geometry.centroid\n",
    "                gdf = gdf_projected.to_crs(epsg=4326)\n",
    "\n",
    "                # Data Extraction\n",
    "                gdf['latitude'] = gdf.geometry.y\n",
    "                gdf['longitude'] = gdf.geometry.x\n",
    "                \n",
    "                # Add source metadata\n",
    "                gdf['source_region'] = region_name\n",
    "\n",
    "                # Column Selection\n",
    "                cols = [\"name\", \"amenity\", \"latitude\", \"longitude\", \"source_region\"]\n",
    "                # Ensure columns exist before selection to avoid errors\n",
    "                existing_cols = [c for c in cols if c in gdf.columns]\n",
    "                \n",
    "                # Append to results list\n",
    "                all_results.append(gdf[existing_cols])\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {region_name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # Return combined results for this batch\n",
    "    if all_results:\n",
    "        return pd.concat(all_results)\n",
    "    else:\n",
    "        # Return empty structure matching schema if nothing found\n",
    "        return pd.DataFrame(columns=[\"name\", \"amenity\", \"latitude\", \"longitude\", \"source_region\"])\n",
    "\n",
    "print(\"Processing function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58c2dee5-1d8b-4c5e-9a6a-dc86e41c1b1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Execution and Save to Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "834deb2e-44e9-4a39-8501-cb80c9253c99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributing tasks across the cluster...\nSaving results to Delta table: world_data_distributed...\n\nSaved results to table: world_data_distributed\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>amenity</th><th>latitude</th><th>longitude</th><th>source_region</th></tr></thead><tbody><tr><td>Red X</td><td>bar</td><td>42.56951904296875</td><td>1.4892706871032717</td><td>Andorra</td></tr><tr><td>null</td><td>bar</td><td>42.577945709228516</td><td>1.4798817634582524</td><td>Andorra</td></tr><tr><td>Bar/Restaurant 360</td><td>bar</td><td>42.57343292236328</td><td>1.4831000566482546</td><td>Andorra</td></tr><tr><td>Cau Bar</td><td>bar</td><td>42.573234558105476</td><td>1.4833889007568362</td><td>Andorra</td></tr><tr><td>El Cabin</td><td>bar</td><td>42.573280334472656</td><td>1.483374476432801</td><td>Andorra</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Red X",
         "bar",
         42.56951904296875,
         1.4892706871032717,
         "Andorra"
        ],
        [
         null,
         "bar",
         42.577945709228516,
         1.4798817634582524,
         "Andorra"
        ],
        [
         "Bar/Restaurant 360",
         "bar",
         42.57343292236328,
         1.4831000566482546,
         "Andorra"
        ],
        [
         "Cau Bar",
         "bar",
         42.573234558105476,
         1.4833889007568362,
         "Andorra"
        ],
        [
         "El Cabin",
         "bar",
         42.573280334472656,
         1.483374476432801,
         "Andorra"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "amenity",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "latitude",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "longitude",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "source_region",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execution & Save\n",
    "print(\"Distributing tasks across the cluster...\")\n",
    "\n",
    "# Create a DataFrame of regions to trigger the parallel process\n",
    "regions_df = spark.createDataFrame([(r,) for r in REGIONS_LIST], [\"region_name\"])\n",
    "\n",
    "# Apply the processing function in parallel\n",
    "# repartition ensures we utilize all available workers\n",
    "final_spark_df = regions_df \\\n",
    "    .repartition(len(REGIONS_LIST)) \\\n",
    "    .groupby(\"region_name\") \\\n",
    "    .applyInPandas(process_region_batch, schema=result_schema)\n",
    "\n",
    "# Save to Delta\n",
    "print(f\"Saving results to Delta table: {OUTPUT_TABLE_NAME}...\")\n",
    "final_spark_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(OUTPUT_TABLE_NAME)\n",
    "\n",
    "print(f\"\\nSaved results to table: {OUTPUT_TABLE_NAME}\")\n",
    "\n",
    "# Display result\n",
    "display(spark.table(OUTPUT_TABLE_NAME).limit(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d978c55c-84cf-4111-94dd-293736539017",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Read Data from Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aec89e96-cd02-4ab5-bd65-cc597a566f9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded - Target table: world_data_distributed\n\nReading data from Delta table...\nSuccessfully loaded 1603 records from database.\nDisplaying sample data:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>amenity</th><th>latitude</th><th>longitude</th><th>source_region</th></tr></thead><tbody><tr><td>Red X</td><td>bar</td><td>42.56951904296875</td><td>1.4892706871032717</td><td>Andorra</td></tr><tr><td>null</td><td>bar</td><td>42.577945709228516</td><td>1.4798817634582524</td><td>Andorra</td></tr><tr><td>Bar/Restaurant 360</td><td>bar</td><td>42.57343292236328</td><td>1.4831000566482546</td><td>Andorra</td></tr><tr><td>Cau Bar</td><td>bar</td><td>42.573234558105476</td><td>1.4833889007568362</td><td>Andorra</td></tr><tr><td>El Cabin</td><td>bar</td><td>42.573280334472656</td><td>1.483374476432801</td><td>Andorra</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Red X",
         "bar",
         42.56951904296875,
         1.4892706871032717,
         "Andorra"
        ],
        [
         null,
         "bar",
         42.577945709228516,
         1.4798817634582524,
         "Andorra"
        ],
        [
         "Bar/Restaurant 360",
         "bar",
         42.57343292236328,
         1.4831000566482546,
         "Andorra"
        ],
        [
         "Cau Bar",
         "bar",
         42.573234558105476,
         1.4833889007568362,
         "Andorra"
        ],
        [
         "El Cabin",
         "bar",
         42.573280334472656,
         1.483374476432801,
         "Andorra"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "amenity",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "latitude",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "longitude",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "source_region",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Retrieval\n",
    "print(f\"Configuration loaded - Target table: {OUTPUT_TABLE_NAME}\\n\")\n",
    "print(f\"Reading data from Delta table...\")\n",
    "try:\n",
    "    # Load data directly from the Delta table (zero network download)\n",
    "    df = spark.table(OUTPUT_TABLE_NAME)\n",
    "    \n",
    "    # Output / Display\n",
    "    count = df.count()\n",
    "    print(f\"Successfully loaded {count} records from database.\")\n",
    "    \n",
    "    print(\"Displaying sample data:\")\n",
    "    display(df.limit(5))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error reading table: {e}\")\n",
    "    print(\"Please verify the table name in the Catalog.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Scale_OSM_to_Delta",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}